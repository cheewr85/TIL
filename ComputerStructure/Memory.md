## Memory

## Roadmap
- [기억장치](#기억장치)
- [메모리 계층구조](#메모리-계층구조)
- [캐시메모리](#캐시메모리)
- [캐시 매핑 방식](#캐시-매핑-방식)
- [반도체 메모리](#반도체-메모리)
- [시스템버스의 대역폭](#시스템버스의-대역폭)

## 기억장치
![one](/img/ComputerStructure/Memory/one.png)


- 메모리(memory, 기억장치)의 역할
	- 프로그램 명령이나 데이터를 저장
	- 프로그램은 메모리에서 활동 중
		- 메인메모리가 클수록 동시에 많은 프로그램을 실행
- 메모리는 프로그램의 작업장
	- 메인메모리는 현재 실행중인 프로그램들을 저장
		- 메모리가 없으면 프로그램이 동작할 수 없음
	- 메모리의 각 영역은 서로 침범하지 못하도록 시스템 소프트웨어의 프로그래머가 정함
		- 프로그래밍 언어로 작성된 텍스트 문서, 데이터 등
		- 필요한 값들을 임시로 저장하는 버퍼나 스택 등
- 램 상주 프로그램(terminate and stay resident, TSR)
	- 실행 후 종료 될 때 제거되는 다른 프로그램들과 달리 메모리에 전체나 일부가 남아 항상 대기
		- 필요할 때 부르면 즉시 나타나 일을 수행
			- 램(RAM)->메인메모리로 사용되는 램 메모리 지칭
	- 운영체제의 커널과 바이러스 백신이 대표적
		- 윈도우 운영체제는 일반적으로 램 상주 프로그램을 실행시킬 필요가 없음
	- 다른 프로그램을 사용할 때 문제가 발생할 수도
		- 바이러스 예방 백신이 램 상주된 경우
			- 다른 프로그램 설치나 하드웨어 장치 사용에 방해
- 메모리를 용도에 따라 분류
	- 주기억장치(main memory, 메인메모리)
		- 혹은 시스템 메모리 -> 프로그램의 동작에 주로 사용
		- 현재 동작하는 프로그램들과 데이터를 저장
			- 전원이 들어온 상태에서 작업이 실행 중일 때 사용
		- 주로 고속의 램 모듈 같은 반도체 메모리 사용
	- 보조기억장치(auxiliary memory)
		- 혹은 2차 기억장치 -> 자료의 저장에 주로 사용
			- 전원이 종료된 후에도 프로그램과 데이터를 안전하게 저장하는 것이 주요 목적
		- 저가격, 대용량이 요구되는 각종 드라이브가 대표적
- 메모리 용량 표시
![two](/img/ComputerStructure/Memory/two.png)
![three](/img/ComputerStructure/Memory/three.png)


- 엔디언(edian, endianness)
	- 메모리 주소와 같은 논리적으로 1차원적인 공간에 여러 개의 연속된 자료를 배열하는 방법
	- 여러 단위로 구성된 자료를 저장할 때
		- 빅 엔디언(big-endian) -> 큰 단위를 먼저 저장
		- 리틀 엔디언(little-endian) -> 작은 단위를 먼저 저장
		- 미들 엔디언(middle 혹은 mixed endian) -> 둘을 혼합
![four](/img/ComputerStructure/Memory/four.png)
![five](/img/ComputerStructure/Memory/five.png)

- 빅 엔디언과 리틀 엔디언 방법
	- 어느 한 쪽이 압도적으로 좋거나 나쁘지 않음
		- 인텔 프로세서는 전통적으로 리틀 엔디언 사용
		- 일반적으로 네트워크 주소는 빅 엔디언 사용
	- 빅 엔디언은 저장 순서가 사람이 숫자 쓰는 방법
		- 프로그래머가 디버깅할 때 편리
	- 리틀 엔디언은 하위 바이트 값만 필요할 때 편리
		- 0x1A2B3C4D 중 0x4D만 읽으면 편리
	- CPU나 소프트웨어에 따라 두 방식을 선택해 사용
		- 바이(bi-), 엔디언 CPU -> 펌웨어로 선택
		- 프로그램 내부에서 바이트 순서를 바꾸어 사용

## 메모리 계층구조
![six](/img/ComputerStructure/Memory/six.png)

- 액세스(access) -> 어떤 장소로 접근하는 동작(사용하는 시간)
	- 이미 저장된 내용을 읽기 위해 혹은 데이터를 새로 저장하기 위해 특정위치에 신호가 도달하는 동작
- 액세스 타임(access time, 접근시간)
	- CPU가 데이터의 저장 위치에 접근을 완료하거나 응답을 받기 시작하는 데 걸린 시간
		- 액세스 타임은 저장된 위치를 찾는데 걸린 시간, 전송속도는 실제 전송이 이루어지는 데이터 전달 속도
	- 기억장치나 입출력장치의 동작속도를 나타내는 척도
		- 액세스 타임이 빠르면 읽기와 쓰기 시간이 절약
		- 같은 장치라도 읽기, 쓰기 액세스 타임이 다를 수 있음
![seven](/img/ComputerStructure/Memory/seven.png)
![eight](/img/ComputerStructure/Memory/eight.png)

- CPU에 가까이 있을수록 빠름, 자주 쓰일스록 속도 빨라짐, 소비전력은 5~8번이 1~4번보다 더 큼

![nine](/img/ComputerStructure/Memory/nine.png)
![ten](/img/ComputerStructure/Memory/ten.png)

- 가상메모리
	- 프로그램이 실행되려면 동작에 필요한 최소한의 메모리가 작업공간으로 남아 있어야 
- 가상메모리(virtual memory, 가상기억장치)
	- 주로 하드디스크의 일부를 확장된 램으로 가정해 부족한 메인메모리의 일부로 사용하는 것
		- 논리적 공간이라 물리적으로 연속적일 필요는 없음
	- 부족한 메인메모리 크기를 외형적으로 늘리는 방법
		- 실제보다 많은 양의 메모리를 갖는 것처럼 동작
	- 운영체제가 자동으로 관리
		- 가상의 주소를 사용해 확장된 램처럼 관리
		- 사용자가 임의로 최대 크기를 설정할 수도

- 하드디스크 스와핑(swapping) 혹은 스왑(swap)
	- 메인메모리의 내용과 보조기억장치인 하드디스크의 내용을 상호 교환하는 것
	- 스왑 파일은 가상메모리를 사용할 때 실제 메모리인 램에 대한 확장으로 하드디스크에 만들어지는 파일
		- 윈도우나 유닉스기반 운영체제들이 사용하는 용어
		- 일반적인 운영체제 -> 페이지, 페이징
	- 파일 단위로 연속된 공간을 구성할 수 있어 적은 횟수의 읽기, 쓰기로 가상메모리를 관리
		- 메모리가 부족하면 오래 전 사용된 내용은 필요할 때까지 임시로 하드디스크에 스왑 파일로 보내짐(안 쓰는 것 카피해서 보냄, 당장 쓰지 않는 부분)
		- 사용자가 스왑 파일의 크기를 조절 할 수도
![eleven](/img/ComputerStructure/Memory/eleven.png)

- 페이지(page), 가상 페이지 
	- 가상메모리 공간을 일정한 크기로 나누어, 메인메모리와 하드디스크 사이에 한 번에 이동하는 단위
		- OS는 다량의 페이지로 구성된 가상메모리를 관리
	- 페이지 프레임(page frame)
		- 가상의 기억공간을 다룰 수 있도록 할당된 메인메모리 영역, 하드디스크의 페이지들 중 하나를 복사해 할당
		- 여러 개의 페이지 프레임들이 존재
	- 페이징(paging), 페이지 교체(replacement)
		- 메인메모리와 하드디스크 사이의 페이지 교환 동작
		- OS가 참고하려는 페이지가 메인메모리에 없으면 하드디스크에 저장해둔 페이지를 참조해 가져옴
![twelve](/img/ComputerStructure/Memory/twelve.png)

- 물리메모리(physical memory)
	- 가상메모리에 대응하는 용어로 실제 메모리
- 가상주소와 물리주소
	- 가상주소(virtual address)
		- 가상메모리를 관리하는 주소
		- 물리주소로 변환해서 사용해야 함
	- 물리주소(physical address)
		- 실제 메모리 주소
		- 오프셋(offset) 값을 이용해 가상주소의 비트 수 줄임
			- 페이지 프레임으로 사용하는 시작주소에서 지정하려는 주소까지 차이인 변위(displacement) 값 알면 계산
![thirteen](/img/ComputerStructure/Memory/thirteen.png)
![fourteen](/img/ComputerStructure/Memory/fourteen.png)
![fifteen](/img/ComputerStructure/Memory/fifteen.png)
![sixteen](/img/ComputerStructure/Memory/sixteen.png)

- 스래싱(thrashing, 과다상태)
	- 전체 시스템 성능이 저하되어 작업의 진전이 아주 느리거나 아예 없는 상태
	- 가상메모리 페이징 동작이 과도하게 일어나는 상태
		- 페이지 교체가 너무 빈번하면 속도가 느린 디스크의 액세스 횟수가 늘어 처리속도가 급격히 떨어짐
	- 메모리나 기타 시스템 자원이 고갈되어 필요한 연산을 수행하기에 너무 부족한 상태
		- 운영체제는 응용프로그램들로부터 자원을 회수하는 방법 등을 통해 이런 문제를 해결하려고 노력

## 캐시메모리
- 캐시메모리(cache memory)
	- 주로 메인메모리의 액세스 타임을 줄이기 위해, CPU와 메인메모리 사이에 사용하는 빠른 속도의 메모리
	- CPU 캐시 혹은 줄여 보통 캐시라고 함
	- 프로그램이 현재 사용 중인 내용의 근방을 저장
		- 자주 액세스하는 데이터나 프로그램 명령을 반복해 검색하지 않고 즉시 사용할 수 있도록 준비(자주 쓰는데이터가 아니면 상당히 비효율적임)
	- 주로 액세스 타임이 빠른 SRAM 사용
	- CPU에 아주 가까운 곳에 위치하거나 아예 내장
		- 1990초부터는 주로 CPU 칩에 내장
- 캐시와 메모리 계층 
	- 캐시로 메모리 계층 간 속도 차이를 완충시켜 전체 기억장치의 평균 액세스 타임을 줄임
	- CPU에 가까운 순서대로 n차 캐시 혹은 레벨 n(level n, Ln)캐시라고 함
	- L3, L2, L1으로 올라갈수록 속도는 증가, 크기는 축소
	- ex)인텔의 3세대 Core i7 프로세서
		- L1,L2,L3로 내려 갈수록 4, 10, 35,40클럭이 소요(내장 캐시의 액세스 타임은 CPU 클럭 개수로 표시)
		- 용량은 32KiB, 256KiB, 8MiB로 커짐
- 아래의 그림은 메모리 계층구조의 일반 형태
	- CPU 고유 부분인 CPU 코어와 함께 L1,L2,L3등의 캐시가 계층구조를 이루며 내장
		- L3 캐시 -> 메인메모리 일부 내용을 저장
		- L2 캐시 -> L3 일부를 저장
		- L1 캐시 -> L2 일부를 저장
	- CPU는 상위계층부터 자료를 찾아 없으면 차례대로 하위계층으로 내려가면서 찾음
		- L1->L2->L3->메인메모리->하드디스크
		- 하위계층에 대한 액세스 횟수가 늘어날수록 평균 속도가 느려져 전체 기억장치의 성능은 저하(미스가 안나도록 해야함)
![seventeen](/img/ComputerStructure/Memory/seventeen.png)

- 같은 CPU 코어에서 캐시가 클수록 성능에 유리
	- 캐시의 위치에 따라 액세스 속도 성능 차이
		- CPU 코어 내부 > CPU 인코어 > CPU 칩 외부 순서
	- 같은 CPU 코어로 프로세서 성능을 개선하는 방법
		- CPU 코어 쿨럭 증가
		- 내장 캐시의 성능 개선 -> 용량과 연결 속도 개선
		- 멀티코어 구조
	- 내장 캐시의 연결 속도 개선 -> 비트 수와 클럭 올림
		- 외부 시스템버스 64비트, 내부 캐시 간 256비트
		- 칩 내부는 외부 시스템버스 쿨럭의 몇 배수 동작
- 온 다이(on-die), 온 칩(on-chip)캐시
	- 온 다이 -> 캐시가 CPU코어와 같은 반도체 회로기판 위에 있다는 뜻(같은 칩 안에 있다는 뜻)
- 멀티코어 프로세서에서 코어(core)의 개념
	- 독립적으로 명령을 실행하는데 필요한 부분
	- ALU, 레지스터, 부동소수점 처리장치(FPU), 독립적인 명령어 실행 장치, 단독으로 사용하는 L1,L2 캐시등
- 언코어(uncore) -> 내장된 장치 중 코어가 아닌 부분
	- 각 코어가 공통으로 공유해 사용할 수 있는 부분 
	- 명령어 인출과 해독장치, L3 공유 캐시와 칩 내부에 내장된 메모리 컨트롤러, 버스 컨트롤러, 그래픽처리장치(GPU)등은 코어개념에서 제외
![eighteen](/img/ComputerStructure/Memory/eighteen.png)

- 디스크 캐시
	- HDD, ODD등 디스크의 액세스 타임을 줄이기 위해 CPU와 디스크 장치 사이에 사용하는 캐시메모리
	- 운영체제에 의해 주로 메인메모리의 일부를 할당
		- 메인메모리의 상당 부분을 할당(많게는 1/3정도)
		- 디스크 캐시 늘리면 메인메모리가 줄어 가상메모리를 늘려야 하므로 적절한 비율을 OS가 자동으로 관리
	- 하드디스크에 내장된 디스크 버퍼
		- HDD를 읽고 쓸 때 임시로 저장해두는 버퍼 메모리
- 메모리의 이중독립버스(dual independent bus)
	- 메모리버스가 두 개의 독립적인 버스를 갖는 구조
		- CPU와 메인메모리 사이의 <외부 시스템버스>
		- CPU 코어와 캐시 사이의 <내부 캐시버스>
	- 전면버스(front-side bus, FSB, 프론트 사이드 버스)
		- 주로 CPU와 외부 메인메모리를 연결하는 시스템버스
		- 램 모듈 속도나 시스템버스의 클럭 등을 언급할 때
	- 후면버스(back-side bus, BSB, 백 사이드 버스)
		- 주로 CPU 내부에 내장된 캐시와 CPU 코어 사이를 연결해주는 캐시버스 
		- FSB보다 비트 수를 넓히고 클럭도 고속으로 설계
- CPU가 액세스한 내용은 일단 캐시에 복사
	- CPU가 요구할 때 신속히 재사용
		- 응용프로그램 사용시 불러들인 파일, 글꼴, 그림들
	- 캐시의 용량에 한계 
		- 한동안 사용되지 않았던 내용은 캐시에서 빠져 나감
	- 캐시 적중(hit)
		- CPU가 원하는 내용을 캐시에서 발견한 상태
		- 캐시에서 CPU로 정보를 읽어옴 
	- 캐시 실패(miss)
		- 원하는 내용이 캐시에 없는 상태
		- 메인메모리나 그 아래 계층에서 읽어옴
![nineteen](/img/ComputerStructure/Memory/nineteen.png)

- 평균 액세스 타임
![twenty](/img/ComputerStructure/Memory/twenty.png)
![twentyone](/img/ComputerStructure/Memory/twentyone.png)

- Ta= H1xT1 + (1-H1)xP1
	- P1 = H2xT2 + (1-H2)xTm

- 캐시는 전체 기억장치의 평균 액세스 타임을 줄이는 목적 -> 상위계층에 데이터가 존재할 확률을 높여야
- 캐시 설계에 고려할 사항 
	- 액세스 타임이 빠른 소자 -> 캐시와 메인메모리
	- 데이터의 지역성
		- 블록 단위로 현재 필요한 정보와 앞으로 예측되는 정보를 함께 인출
	- 캐시와 메인메모리의 데이터 일관성
		- 캐시의 내용을 변경할 때 메인메모리의 내용을 함께 바꾸어 주어야 -> 이때 걸리는 시간을 최소화
	- CPU 발열문제 : 적중률 높아지면 소비전력, 발열량도 높아짐
![twentytwo](/img/ComputerStructure/Memory/twentytwo.png)

- idea -> 짧은 시간을 기준으로 보면 CPU가 자주 액세스하는 메모리 위치는 주로 한정된 지역에 집중
	- 시간적 지역성(temporal locality)
		- CPU에서 한번 참조한 프로그램이나 데이터는 조만간 다시 참조될 가능성이 높음
			- 짧은 시간 내 특정 데이터나 자원을 재사용하는 현상
	- 공간적 지역성(spatial locality)
		- 한번 참조된 데이터 주변에 인접한 데이터는 같이 참조될 가능성이 높음 -> 인접 저장된 배열 데이터
		- 대부분의 프로그램 명령어는 분기가 발생하기 전까지 기억장치에 저장된 순서대로 실행
			- 이를 순차적 지역성이라 부름
- 메인메모리와 캐시 간 데이터 일관성
	- 메인메모리와 복사본인 캐시는 데이터의 일관성이 유지 관리되고, 이때 걸리는 시간도 최소화해야
		- CPU는 본래 메인메모리를 액세스하려고 한 것
		- 캐시는 액세스 속도를 빠르게 해줄 목적
	- 정상적인 캐시는 메인메모리 자료의 일부 복사본
		- 본래는 메인메모리도 같은 내용을 가지고 있어야
	- 캐시가 갱신될 때 메인메모리도 함께 갱신되어야 둘 사이의 매핑 구조가 정상적으로 유지
		- 캐시만 갱신되고 메인메모리가 갱신되지 않으면
			- 서로 다른 내용을 가져 잘못된 결과를 초래할 수도
- 캐시 쓰기 정책(write policy)
	- 캐시의 블록이 변경되었을 때 메인메모리의 블록을 갱신(update)하는 방법과 시기를 정하는 것
- 연속기록(write-through)캐시
	- CPU가 캐시와 메인메모리 두 군데 데이터를 정상적으로 함께 갱신하는 방식
	- 속도가 빠른 캐시가 먼저 업데이트 된 후 느린 메인 메모리에 기록이 완료
		- 구조는 간단하지만 캐시가 갱신될 때, 느린 메인메모리를 매번 함께 액세스하므로 성능 저하
		- 가상메모리에 적용하면 시간이 더욱 오래 걸림
- 후기록(write-back)캐시
	- CPU가 캐시의 데이터만 우선 변경하고 메인메모리는 나중에 갱신하는 방식
		- 캐시의 자료가 교체될 때 메인메모리에 없는 내용이면 메인메모리로 복사한 후 캐시에서 비움 
	- 메인메모리로의 백업은 CPU 기계 사이클이 대기 상태로 여유가 있을 때 블록단위로 수시로 미리 백업
		- 하드웨어가 복잡하고 데이터가 갱신되기 전까지 메인메모리의 일부 내용이 일시적으로 무효
	- 요즘 프로세서들은 대개 Write-back 캐시 방법 사용
		- 느린 메인메모리의 쓰기 동작을 최대한 줄여 시간절약
![twentythree](/img/ComputerStructure/Memory/twentythree.png)
![twentyfour](/img/ComputerStructure/Memory/twentyfour.png)

- 캐시 알고리즘(cache algorithm) 혹은 교체 정책(replacement policy)
	- 캐시의 내용 중 교체되어 나갈 자료를 결정하는 것
		- 캐시 적중에 실패했을 때 캐시에 공간이 부족하면 저장된 자료를 바꾸어 주어야 함
	- 가장 이상적인 목표는 미래에 가장 오랫동안 필요로 하지 않는 자료를 교체하는 것
		- 이것을 예측하는 것은 일반적으로 불가능 
	- 캐시의 매핑 방식도 넓은 의미로 교체 정책에 포함
![twentyfive](/img/ComputerStructure/Memory/twentyfive.png)
![twentysix](/img/ComputerStructure/Memory/twentysix.png)
![twentyseven](/img/ComputerStructure/Memory/twentyseven.png)

## 캐시 매핑 방식
- 데이터 블록과 캐시 라인
	- 메인메모리 용량 > 캐시 용량(capacity)
		- 메인메모리는 데이터 블록(data block)으로 나누어짐
			- 다수의 데이터 블록들이 캐시를 공유해 사용
			- 메인메모리와 캐시 사이의 전송은 데이터 블록 단위
		- 데이터 블록 하나는 여러 개의 워드(word)로 구성
			- 워드 크기는 메모리 주소 하나에 할당되는 비트 수로 주로 1바이트 사용
		- 캐시메모리의 캐시 라인
			- 캐시메모리를 구성하는 행
			- 메인메모리의 데이터 블록 중 하나를 저장
			- 캐시의 데이터 교체는 캐시라인 단위
![twentyeight](/img/ComputerStructure/Memory/twentyeight.png)
![twentynine](/img/ComputerStructure/Memory/twentynine.png)

- 캐시의 매핑 방식
	- 메인메모리에 있는 다수의 데이터 블록들이 소수의 캐시 라인을 공유하는 방법
		- 메인메모리와 캐시의 자료를 대응시키는 방법 
	- CPU가 발생시킨 메인메모리 주소와 캐시 라인 자료를 1:1로 매핑
		- 완전연관(fully asscociative) 캐시 -> 메인메모리의 데이터 블록이 아무 캐시 라인에나 들어감
		- 직접매핑(direct-mapped) 캐시 -> 데이터 블록이 지정된 캐시 라인에만 들어감
		- 세트연관(set-associative) 캐시 -> 데이터 블록이 복수의 캐시 라인을 묶은 지정된 세트에만 들어감
![thirty](/img/ComputerStructure/Memory/thirty.png)
![thirtyone](/img/ComputerStructure/Memory/thirtyone.png)

- 완전 연관 캐시
	- 메인메모리의 데이터 블록이 모든 캐시라인에 들어감
		- CPU가 발생시킨 메인메모리 주소가 모든 캐시 라인에 포함된 블록 내의 워드로 매핑
	- 가상의 메인메모리 주소 형식의 필드 정의
		- 태그 필드 -> 캐시 라인에 들어갈 메인 메모리 블록 선택 
		- 블록 오프셋 필드 -> 블록에 포함된 워드를 선택
		
![thirtytwo](/img/ComputerStructure/Memory/thirtytwo.png)

- 캐시 적중여부 검사
	- 모든 캐시 라인의 1.태그를 조사해 메인메모리 주소의 태그 필드와 일치하는 것이 있는지 검사
		- 일치하는 것이 있으면 적중이고 없으면 실패
	- 적중하면
		- 2.블록 오프셋 필드 값을 이용해 해당 캐시 라인의 워드 중 하나를 골라 읽거나 씀
	- 실패하면
		- 메인메모리에서 원하는 주소의 데이터를 읽거나 쓰고
		- 새로 사용된 메인메모리의 해당 블록을 비어있거나 교체될 캐시 라인에 넣어주고 태그 비트를 고침
![thirtythree](/img/ComputerStructure/Memory/thirtythree.png)

- 직접매핑 캐시
	- 직접매핑 캐시는 메인메모리의 데이터 블록이 지정된 캐시 라인에만 들어감
		- CPU가 발생시킨 메인메모리 주소가 지정된 캐시 라인에 포함된 블록 내의 워드로 매핑
		- 인덱스 필드 -> 캐시 라인을 선택 
		- 태그 필드 -> 캐시 라인에 들어갈 메인 메모리 블록 선택
		- 블록 오프셋 필드 -> 블록에 포함된 워드를 선택
![thirtyfour](/img/ComputerStructure/Memory/thirtyfour.png)

- 캐시 적중여부 검사
	- 1.인덱스 필드로 캐시 라인을 먼저 선택 
	- 선택된 캐시 라인의 태그를 조사해 메인메모리 주소의 2.태그 필드와 일치하는지 검사
		- 일치하면 적중이고 아니면 실패
	- 적중하면
		- 3.블록 오프셋 필드 값을 이용해 해당 캐시 라인의 워드 중 하나를 골라 읽거나 씀
	- 실패하면
		- 메인메모리에서 원하는 주소의 데이터를 읽거나 쓰고
		- 새로 사용된 메인메모리의 해당 블록을 지정된 캐시라인에 넣어주고 태그 비트를 고침
![thirtyfive](/img/ComputerStructure/Memory/thirtyfive.png)

- 세트연관 캐시
	- 세트연관 캐시는 메인메모리의 데이터 블록이 복수의 캐시 라인을 묶은 지정된 세트에만 들어감
		- CPU가 발생시킨 메인메모리 주소가 지정된 세트에 포함된 블록 내의 워드로 매핑
		- 세트 필드 -> 세트를 선택
		- 태그 필드 -> 캐시 라인에 들어갈 메인메모리 블록 선택
		- 블록 오프셋 필드 -> 블록에 포함된 워드를 선택
![thirtysix](/img/ComputerStructure/Memory/thirtysix.png)

- 캐시 적중여부 검사
	- 1.세트 필드로 세트를 먼저 선택
	- 세트 내 모든 캐시 라인의 태그를 조사, 메인메모리 주소의 2.태그 필드와 일치하는 것이 있는지 검사
		- 일치하는 것이 있으면 적중이고 없으면 실패
	- 적중하면
		- 3.블록 오프셋 필드 값을 이용해 해당 캐시 라인의 워드 중 하나를 골라 읽거나 씀
	- 실패하면
		- 메인메모리에서 원하는 주소의 데이터를 읽거나 쓰고
		- 새로 사용된 메인메모리 블록을 지정된 세트에서 비어있거나 교체될 캐시 라인에 넣고 태그 비트 고침
![thirtyseven](/img/ComputerStructure/Memory/thirtyseven.png)

- 세트연관 캐시와 연관도
	- 세트연관 캐시 방식의 종류
		- 2-방향(2-way) 세트연관 캐시
			- 각 세트가 2개의 캐시 라인을 갖는 경우
		- n-방향(n-way) 세트연관 캐시
			- 각 세트가 n개의 캐시 라인을 갖는 경우
	- 연관도
		- 세트를 구성하는 way 수 n
			- 세트 수 = 캐시라인 수 / way 수의 관계
		- 캐시 전체가 하나의 세트가 되면
			- n이 최대가 되는 완전연관 캐시
		- 연관도가 커지면 하드웨어가 복잡해짐
![thirtyeight](/img/ComputerStructure/Memory/thirtyeight.png)
![thirtynine](/img/ComputerStructure/Memory/thirtynine.png)
![fourty](/img/ComputerStructure/Memory/fourty.png)

- 가상메모리를 메인메모리에 매핑하는 방법
	- 프로그램에 의해 발생하는 가상주소를 메인메모리에 있는 물리주소로 변환하는 과정이 필요
		- 프로세서 칩에 내장된 MMU 장치가 TLB에 저장된 내용으로 이를 수행
	- MMU(memory management unit)
		- 메모리 관리 장치의 영문약자, 물리주소 변환과 메모리 보호가 주요 역할
		- 메모리 접근권한을 제어해 메모리를 보호하고 캐시 관리, 버스 중재 등의 역할도 수행
	- TLB(translation lookaside buffer)
		- 최근에 일어난 가상 메모리 주소와 물리 주소의 변환 테이블을 저장하는 일종의 주소 변환 캐시
		- 변환 색인 버퍼의 영문약자, 가상주소로 이에 해당하는 물리주소를 검색할 때 사용되는 버퍼 메모리
		- 페이지 테이블에 대한 일종의 캐시 역할
			- 운영체제가 저장해둔 페이지 테이블의 일부를 검색속도가 빠른 CPU 내부로 복사해온 것
			- 페이지 테이블 이용을 생략해 여러 메모리 내용을 읽고 물리주소를 계산하던 주소변환 시간을 줄일 목적
		- TLB 내용은 메인메모리의 일부 페이지 프레임에 저장된 가상메모리의 일부 페이지를 표시한 정보
			- 각항의 내용은 페이지 테이블처럼 하나의 페이지 번호가 하나의 페이지 프레임 번호로 1:1 매핑
![fourtyone](/img/ComputerStructure/Memory/fourtyone.png)
![fourtytwo](/img/ComputerStructure/Memory/fourtytwo.png)

- 가상주소를 물리주소로 변환
	- CPU가 요청한 가상주소 발생 -> 먼저 TLB 검사
		- TLB에 있으면 TLB 적중(hit), 없으면 TLB 실패(miss)
	- TLB 실패면 -> 페이지 테이블 검사해 정보가 있으면
		- 가져오고 TLB 갱신, 주소변환 정보가 없으면
	- 페이지 폴트(page fault, 페이지 부재)
		- 가상주소 페이지가 메인메모리에 없는 경우 -> OS가 HDD에서 메인메모리로 새로운 페이지를 전송
		- 메인메모리에 빈 페이지 프레임이 있으면 새로운 페이지를 적재(load), 빈 공간 없으면 기존 페이지와 교체
	- 페이지 테이블 갱신 후 최종 물리주소 변환 완료
		- 페이지 부재는 메모리 보호 목적으로도 사용 -> 허락 받지 않은 프로그램이 접근하면 일부러 일으켜 차단
![fourtythree](/img/ComputerStructure/Memory/fourtythree.png)
![fourtyfour](/img/ComputerStructure/Memory/fourtyfour.png)

- 가상주소 캐시
	- 가상주소 캐시의 동작
		- 가상메모리를 사용하는 CPU는 MMU에 가상주소를 발생하고, MMU는 가상주소 캐시를 먼저 확인
			- 가상주소 캐시 안에 물리주소로 변환할 가상주소가 존재하면 MMU가 물리주소를 그대로 가져다 사용
		- 물리캐시가 캐시 적중 여부를 확인하는 시간을 줄임
			- 물리캐시는 적중을 확인하기 위해 반드시 TLB에서 가상주소를 물리주소로 변환하는 계산과정이 추가 필요
		- 가상주소 캐시의 적중과 실패
			- CPU각 요청한 가상주소가 가상주소 캐시 안에서 발견되면 적중 -> MMU가 물리메모리의 검색 속도를 높임
			- 실패면 TLB를 확인 -> 이하 과정은 앞의 방법과 동일

## 반도체 메모리
![fourtyfive](/img/ComputerStructure/Memory/fourtyfive.png)

- 메모리 셀(cell)
	- 디지털 정보의 최소 단위인 1비트를 저장하는 소자
- 메모리 워드(word)
	- 1,2,4,8,16,32,64,128비트로 커지며 칩의 설계마다 다름
- 저장 용량(capacity)
	- 저장매체에 저장된 정보비트의 수량
		- 개별 메모리 칩은 대개 비트 단위로 표시
		- 메인메모리용 램 모듈은 주로 바이트 단위로 표시
	- 반도체 업체들은 과거의 용량 단위를 고집
- 칩이나 램 모듈의 저장 구조
	- 저장 주소의 개수와 메모리 워드의 비트 수를 곱해 (주소 수)x(비트 수)로 저장 밀도 표시
		- 메모리 칩 구조 256Mx4 -> 256M(2^28)개 저장 주소, 4(2^2)비트의 메모리 워드를 갖는 1Gib(2^30) 용량
- 메모리 뱅크 
	- 기억장치를 분할해 독립적으로 액세스 할 수 있도록 구성한 논리적인 단위, 한번에 하나의 뱅크만 액세스
		- CPU가 메모리의 한 뱅크를 사용할 때 입출력장치가 다른 뱅크를 사용할 수 있어 효율적
	- 뱅크의 크기는 논리적이라 구성하기 나름 
		- 메모리 칩 내부에도 여러 개의 뱅크를 가질 수 있음
- 전형적인 DRAM 칩에서 뱅크
	- 여러 개의 행과 열로 구성된 격자구조의 저장 단위
	- 램 모듈은 이런 구조가 여러 개의 칩에 걸쳐 연결
- 메모리 칩 내부의 저장 위치 구조 
	- 뱅크 수 x 행수 x 열수
		- 칩 내부의 저장 주소의 총 개수
	- 뱅크 내부는 행수 x 열수의 메모리 격자구조
- 메인보드의 램 모듈도 뱅크로 구분할 수 있음
	- 메모리 컨트롤러와 이를 장착할 메모리 슬롯의 물리적인 구조에 의해 결정
- ROM(read only memory, 롬)
	- 읽기 전용 메모리의 영문약자
	- 보통의 방법으로는 읽을 수만 있는 메모리
	- 전원이 없어도 내용이 지워지지 않는 비휘발성(non-volatile, NV) 메모리의 일종
	- 내용이 쉽게 변경되지 않아야 할 프로그램들 저장
		- 시스템 시동과 관련된 초기화 프로그램, 진단 프로그램, 시스템에서 자주 호출하는 서브루틴, CPU 내부 제어장치의 마이크로프로그램 등
- RAM
	- 읽기 쓰기 메모리의 영문 약자
		- RWM(read write memory)은 실제 잘 사용되지 않음
	- ROM과 반대되는 용어로 보통 RAM을 사용
		- 일반적으로 RAM은 데이터 보존을 위해 전원이 필요한 휘발성 메모리를 통칭하는 말
		- NVRAM(non-valatile RAM)
			- 데이터를 보존하는데 전원이 필요 없고 읽고 쓰기도 가능한 메모리로 비휘발성 램의 영문약자
- RAM(random access memory, 램)
	- 찾는 주소에 따라 액세스 타임이 일정한 메모리
	- 무순 접근 메모리의 영문약자
	- 반도체 메모리와 자기디스크 등 대부분의 기억장치
- SAM(sequential access memory, 샘)
	- 찾는 주소에 따라 액세스 타임이 변하는 메모리
	- 순차 접근 메모리의 영문약자
	- 자기 테이프 등 일부에서 해당
		- ex. 음악 CD는 RAM 방식이라 곡을 지정하면 어떤 곡이든 나오는데 걸리는 시간이 일정
		- ex. 음악 테이프는 SAM 방식이라 테이프를 감아야 하므로 곡마다 나오는데 걸리는 시간이 다름
- 반도체 ROM의 종류
![fourtysix](/img/ComputerStructure/Memory/fourtysix.png)
![fourtyseven](/img/ComputerStructure/Memory/fourtyseven.png)


- 플래시 메모리(flash memory)
	- 대중적인 비휘발성 램(NVRAM), EEPROM의 한 형태지만 과거 전통 방식 소자들과 구분되는 장점
		- EEPROM과 달리 큰 블록 크기들을 사용할 수 있어 지우는 속도가 빠르고 일괄 소거 가능, 특히 가격 저렴
	- 메모리 카드가 들어가는 디지털 카메라, 휴대전화 등 각종 휴대용 기기와 USB 드라이브 등에 널리 쓰임
		- 아직 가격이 문제이나 이동용 컴퓨터부터 물리적으로 취약하고 부피가 큰 HDD를 빠르게 대체
	- 기존 디지털 기기의 설정 값을 저장하는 용도로 쓰이던 EEPROM과 배터리 백업 받던 SRAM을 대체
	- 플로팅게이트(floating gate)의 충전과 방전을 이용하여 1소자당 1비트인 간단한 구성 
		- DRAM보다 -> 단위 셀 면적이 작아 대용량에 유리하고 소비전력도 작고 저렴하나, 특히 쓰기 속도는 느림
		- 메모리 내부 셀이 NAND와 NOR 논리 게이트와 유사
	- NAND 타입 
		- 몇 개의 블록 단위로 읽고 쓸 수 있음
		- 대용량이 요구되는 메모리 카드, USB 드라이브 등
	- NOR 타입
		- 대개 바이트인 메모리 워드 단위로 읽고 쓸 수 있음
		- 과거 EPROM을 대체하여 빠른 속도가 요구되는 기계어 코드 수준의 응용설계에 주로 사용
![fourtyeight](/img/ComputerStructure/Memory/fourtyeight.png)
![fourtynine](/img/ComputerStructure/Memory/fourtynine.png)

- 사이클 타임
	- 메모리 용어에서 기억장치에서 연이은 액세스를 새로 시작하는데 걸리는 시간 간격
	- SRAM -> 사이클 타임 = 액세스 타임
	- DRAM -> 사이클 타임 = 액세스 타임 x2
		- 리프레시 진행되는 동안 새로운 액세스를 시작할 수 없어 연속 액세스하려면 액세스 타임의 2배 정도 필요
- DRAM 구조
![fifty](/img/ComputerStructure/Memory/fifty.png)
![fiftyone](/img/ComputerStructure/Memory/fiftyone.png)

- DRAM 리프레시
	- RAS가 가해진 모든 행에 걸린 셀의 내용이 한 번에 재충전되는 방식 등을 사용
		- 리프레시가 차지하는 시간은 전체 사용의 1~2% 정도
	- 재충전 시간 때문에 DRAM을 연속 액세스하려면
		- 액세스 타임의 2배 정도 필요
	- 특정 셀의 내용을 읽어오면 출력으로 전압이 떨어져 강제로 재충전 해주어야 하고
	- 특정 셀에 쓰면 그 행에 걸린 모든 열의 셀이 재충전되므로 기다려야 함
- 램 모듈(RAM module), 메모리 모듈
	- 주로 컴퓨터의 메인메모리로 사용하기 위해 시스템보드에 장착하기 적합하도록 만들어진 부품
		- 대개 DRAM 칩을 결합한 보드형태로 메인보드에 장착
	- 메모리 랭크(rank)
		- 공통의 버스에 연결되어 동시에 동작하는 칩들의 모임
		- 주로 같은 칩 선택 신호에 연결되어 동시에 액세스가 가능한 DRAM 칩들의 집합
		- 메모리 칩들은 모두 같은 메모리 주소버스와 데이터버스에 연결되지만 물리적으로 여러 랭크로 나눔
![fiftytwo](/img/ComputerStructure/Memory/fiftytwo.png)
![fiftythree](/img/ComputerStructure/Memory/fiftythree.png)

- 램 모듈의 저장 구조(organization)
	- 칩의 구조처럼 저장 주소의 개수와 데이터버스의 비트 수를 곱함 -> 주소 수 x 비트 수
	- 1G x 64 표시 램 모듈 -> 1G개 저장 주소와 64비트 데이터버스로 구성된 8GiB 용량의 램 모듈
- 램 모듈의 구성(composition)
	- 칩의 저장 구조에 칩의 수를 곱해 -> 주소 수 x 비트 수 x 칩의 개수로 표시
	- 512M x 8 x 16pcs로 표시된 64비트 램 모듈의 구성 -> 512M x 8 구조의 8비트 4Gib 칩 16개(pieces)
		- 64비트를 위해 랭크 하나에 64/8 = 8개의 칩 필요
		- 16개 칩은 16/8 = 2개의 랭크로 나누어짐
![fiftyfour](/img/ComputerStructure/Memory/fiftyfour.png)
![fiftyfive](/img/ComputerStructure/Memory/fiftyfive.png)
![fiftysix](/img/ComputerStructure/Memory/fiftysix.png)

- SDRAM(synchronous DRAM, 에스디램)
	- 메모리 컨트롤러가 아닌 메모리 버스 클럭에 직접 동기(synchronous)되는 DRAM
- DDR(double data rate) SDRAM
	- 같은 메모리 클럭 속도에서 SDRAM에 비해 2배의 데이터 전송률을 갖는 DRAM
		- 클럭 펄스의 상승, 하강 시점에서 2번의 데이터 전송
		- 클럭 속도가 물리적으로 증가하는 것은 아니지만 버스사이클 하나당 전송횟수를 늘려 대역폭을 증가
![fiftyseven](/img/ComputerStructure/Memory/fiftyseven.png)

- 반도체 칩의 클럭 승수(clock multiplier)
	- 반도체 칩 내부의 동작 클럭이 외부 공급 클럭의 몇 배수인가를 표시 xn
		- DDR2, DDR3, DDR4의 클럭 승수는 각각 x2, x4, x8 -> 각 클럭의 상승과 하강에서 2번의 전송을 일으켜 데이터 전송률은 SDRAM에 비해 x4, x8, x16배
- 선인출(prefetch, 프리패치)
	- 작업이 빨리 실행되도록 필요한 자료를 미리 읽어 들이는 기능
	- DDR 방식은 선인출 버퍼에 여러 비트를 미리 준비해 한 메모리버스 사이클 당 여러 번의 데이터 전송
		- 선인출 버퍼의 입출력 비트 수는 사이클당 전송횟수

![fiftynine](/img/ComputerStructure/Memory/fiftynine.png)
![sixty](/img/ComputerStructure/Memory/sixty.png)
![sixtyone](/img/ComputerStructure/Memory/sixtyone.png)
![sixtytwo](/img/ComputerStructure/Memory/sixtytwo.png)
![sixtythree](/img/ComputerStructure/Memory/sixtythree.png)

## 시스템버스의 대역폭
![sixtyfour](/img/ComputerStructure/Memory/sixtyfour.png)

- 데이터 전송속도
	- 전문적인 용어는 데이터 전송률(data transfer rate)
		- 줄여 데이터율(data rate), 전송률(transfer rate)
		- 본래 정의는 단위 시간당 전송되는 정보량
		- 모든 단위 시간이나 단위 정보량을 통칭 -> 초당 비트수, 초당 바이트 수, 분당 비트 수, 분당 바이트 수등
	- 비트율이 가장 많이 사용되어 대표적인 이름이 됨
		- data transfer rate -> data rate -> bit rate
		- 본래는 단위 시간당 전송되는 비트 수 이지만
		- 비트율의 단위로 초당 비트 수(bit/s)와 초당 바이트 수(B/s)를 함께 사용
![sixtyfive](/img/ComputerStructure/Memory/sixtyfive.png)

- 대역폭의 2가지 정의
	- 통신, 신호처리 분야에서 신호의 대역폭(bandwidth)
		- 해당 신호의 전달에 사용되는 주파수(frequency)의 폭
		- 도로의 폭처럼 신호를 전송할 때 필요한 주파수의 폭
	- 컴퓨터 분야에서 채널의 대역폭(bandwidth)
		- 채널의 이론적인 최대 전송속도, 채널의 전송능력
		- 비트율로 표시
			- 비트율이 어떤 특정 신호의 전송속도라면,
			- 대역폭은 그 채널이 허용하는 이론적인 최대 전송속도
		- 해당 채널이 허용하는 최대 전송속도 -> 통신 분야에서는 이를 별도로 채널 용량(channel capacity)이라 함
		- 버스의 대역폭(bit/s) = 버스의 클럭률(Hz) x 비트 수
		- 버스의 클럭률(Hz) = 실제 클럭 속도(Hz) x 사이클당 전송횟수
	- 버스의 클럭률 -> 버스의 실제 물리적인 클럭 속도와 버스의 한 사이클당 전송횟수를 곱해 계산
		- 실제 물리적으로 적용되는 클럭 속도가 아님
			- 한 번의 버스 사이클 동안 여러 번의 데이터 전송을 실시해 마치 그런 효과를 갖는다고 할 수 있음
		- 램 모듈 제조자들은 FSB의 클럭률을 제품에 표시 
			- DDR3 1600MHz 램 모듈 -> 실제 물리적인 클럭속도 200MHz에서 한 번의 버스 사이클 동안 8번의 데이터 전송을 실시, 200MHz x 8 = 1600MHz 클럭률 효과
![sixtysix](/img/ComputerStructure/Memory/sixtysix.png)